#!/usr/bin/python3
import contextlib
import hashlib
import json
import os
import pathlib
import subprocess
import sys
import tempfile


def write_repofile(f, repoid, repo, keydir):
    f.write(f"[{repoid}]\n")

    def write_option(key, value):
        f.write(f"{key}={value}\n")

    # silence dnf warning about missing name
    write_option("name", repoid)

    for key in ("metalink", "mirrorlist", "baseurl"):
        value = repo.get(key)
        if value:
            write_option(key, value)

    if "gpgkey" in repo:
        keyfile = f"{keydir}/{repoid}.asc"
        with open(keyfile, "w") as key:
            key.write(repo["gpgkey"])
        write_option("gpgcheck", 1)
        write_option("gpgkey", f"file://{keyfile}")


def dnf_cachedir(repoid, repo, releasever, basearch):
    """Return the relative cache directory for a repository.

    Using the same algorithm as libdnf:

        https://github.com/rpm-software-management/libdnf/blob/master/libdnf/repo/Repo.cpp#L1288
    """

    if "metalink" in repo:
        url = repo["metalink"]
    elif "mirrorlist" in repo:
        url = repo["mirrorlist"]
    elif "baseurl" in repo:
        url = repo["baseurl"]
    else:
        raise RuntimeError(f"one of metalink, mirrorlist, or baseurl must be given for repository '{repoid}'")

    url = url.replace("$basearch", basearch).replace("$releasever", releasever)
    digest = hashlib.sha256(url.encode()).hexdigest()[:16]

    return f"{repoid}-{digest}"


def main(tree, options):
    repos = options["repos"]
    packages = options["packages"]
    releasever = options["releasever"]
    basearch = options["basearch"]
    operation = options.get("operation", "install")
    weak_deps = options.get("install_weak_deps", True)
    exclude_packages = options.get("exclude_packages", [])

    script = f"""
        set -e
        mkdir -p {tree}/dev {tree}/sys {tree}/proc
        mount -o bind /dev {tree}/dev
        mount -o bind /sys {tree}/sys
        mount -o bind /proc {tree}/proc
    """

    machine_id_set_previously = os.path.exists(f"{tree}/etc/machine-id")
    if not machine_id_set_previously:
        # create a fake machine ID to improve reproducibility
        print("creating a fake machine id")
        script += f"""
            mkdir -p {tree}/etc
            echo "ffffffffffffffffffffffffffffffff" > {tree}/etc/machine-id
            chmod 0444 {tree}/etc/machine-id
        """

    try:
        subprocess.run(["/bin/sh", "-c", script], check=True)
    except subprocess.CalledProcessError as err:
        print(f"setting up API VFS in target tree failed: {err.returncode}")
        return err.returncode

    with tempfile.TemporaryDirectory(prefix="org.osbuild.dnf.") as confdir:
        dnfconf = f"{confdir}/dnf.conf"

        with open(dnfconf, "w") as conf:
            for num, repo in enumerate(repos):
                write_repofile(conf, f"repo{num}", repo, confdir)

        base_cmd = [
            "dnf", "-yv",
            "--installroot", tree,
            "--forcearch", basearch,
            "--setopt", "reposdir=",
            "--setopt", f"install_weak_deps={weak_deps}",
            "--releasever", releasever,
            "--disableplugin=generate_completion_cache", # supress error that completion db can't be opened
            "--config", dnfconf
        ]

        cmd = base_cmd + [operation] + packages
        for x in exclude_packages:
            cmd += ["--exclude", x]
        print(" ".join(cmd), flush=True)
        subprocess.run(cmd, check=True)

    # verify metadata checksum
    for repoid, repo in enumerate(repos):
        algorithm, checksum = repo["checksum"].split(":")
        assert algorithm == "sha256"
        cachedir = dnf_cachedir(f"repo{repoid}", repo, releasever, basearch)
        with open(f"{tree}/var/cache/dnf/{cachedir}/repodata/repomd.xml", "rb") as f:
            repomd = f.read()
        assert hashlib.sha256(repomd).hexdigest() == checksum

    # delete cache manually, because `dnf clean all` leaves some contents behind
    fd = os.open(f"{tree}/var/cache/dnf", os.O_DIRECTORY)
    for _, dirs, files, dirfd in os.fwalk(".", topdown=False, dir_fd=fd):
        for name in files:
            os.unlink(name, dir_fd=dirfd)
        for name in dirs:
            os.rmdir(name, dir_fd=dirfd)
    os.close(fd)

    # remove temporary machine ID if it was created by us
    if not machine_id_set_previously:
        print("deleting the fake machine id")
        machine_id_file = pathlib.Path(f"{tree}/etc/machine-id")
        machine_id_file.unlink()
        machine_id_file.touch()

    # remove random seed from the tree if exists
    with contextlib.suppress(FileNotFoundError):
        os.unlink(f"{tree}/var/lib/systemd/random-seed")

    return 0


if __name__ == '__main__':
    args = json.load(sys.stdin)
    r = main(args["tree"], args["options"])
    sys.exit(r)
